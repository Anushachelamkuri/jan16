<html>
    <head>
        <title> </title>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="style.css">
    </head>
    <body>
        <div>
        </div>
        <p style="text-align: right;">(196-200)pages</p>
        <ul style="text-align:start";>
            <li>Jenkins, C. R., and Dillman, D. A. (1997). Towards a theory of self-administered questionnaire design. In E. Lyberg, P. Bierner, M. Collins, D. Leeuw, C. Dippo, N. Schwartz
& D. Trewin (Eds.), Survey measurement and process quality. New York: John
Wiley & Sons</li><br>
        <li>Kalton, G. & Kasprzyk, D. (1982). Imputing for missing survey responses. In the
Proceedings of the Section on Survey Research Methods, Alexandria, VA: American Statistical Association, pp.22-31.</li><br>
            <li>Kalton, G. & Kish, L. (1981). Two efficient random imputation procedures. In the
Proceedings of the Survey Research Methods Section, Alexandria, VA: American
Statistical Association, pp.146-151.</li><br>
            <li>Kass, G. (1980). An exploratory technique for investigating large quantities of categorical data, Applied Statistic</li><br>
            <li>Kim, Y. (2001). The curse of the missing data [Online]. Available http://209.68.240.11:8080/
2ndMoment/978476655/addPostingForm [2001, September 1].</li><br>
            <li>Li, K. (1985). Hypothesis testing in multiple imputation - With emphasis on mixed-up
frequencies in contingency tables, Ph.D.Thesis, The University of Chicago,
Chicago, IL .</li><br>
            <li>Little, R. (1982). Models for nonresponse in sample surveys. Journal of the American
Statistical Association, 77, 237-250.</li><br>
            <li>Little, R. (1992). Regression with missing X’s: A review. Journal of the American
Statistical Association, 87, 1227-1237</li><br>
            <li>Little, R. (1995). Modeling the drop-out mechanism in repeated-measures studies.
Journal of the American Statistical Association, 90, 1112-1121.</li><br>
            <li>Little, R. & Rubin, D. (1987). Statistical analysis with missing data. New York: Wiley.
Little, R. & Rubin, D. (1989). The analysis of social science data with missing values.
Sociological Methods and Research, 18, 292-326.</li><br>
            <li>Loh, W. & Shih, Y. (1997). Split selection methods for classification trees. Statistica
Sinica, 7, 815-840.</li><br>
            <li>Loh, W. & Vanichestakul, N. (1988). Tree-structured classification via generalized
discriminant analysis (with discussion). Journal of the American Statistical
Association 83, 715-728.</li><br>
            <li>Masters, T. (1995). Neural, novel, and hybrid algorithms for time series predictions.
New York: Wiley.</li><br>
            <li>Michalewicz, Z. (1994). Genetic algorithms + data structures = evolution programs.
New York: Springer-Verlag.</li><br>
            <li>Morgan, J. & Messenger, R. (1973). THAID: A sequential analysis program for the
analysis of nominal scale dependent variables. Technical report, Institute of Social
Research, University of Michigan, Ann Arbor, MI.</li><br>
            <li>Morgan, J. & Sonquist, J. (1973). Problems in the analysis of survey data and a proposal.
Journal of the American Statistical Association, 58, 415-434.</li><br>
            <li>Nie, N., Hull, C., Jenkins, J., Steinbrenner, K., & Bent, D. (1975). SPSS, 2nd ed. New York:
McGraw-Hill.</li><br>
            <li>Orchard, T. & Woodbury, M. (1972). A missing information principle: Theory and
applications. In the Proceedings of the 6th Berkeley Symposium on Mathematical
Statistics and Probability, University of California, Berkeley, CA, 1, 697-715.</li><br>
            <li>Pennell, S. (1993). Cross-sectional imputation and longitudinal editing procedures in the
survey of income and program participation. Technical report, Institute of Social
Research, University of Michigan, Ann Arbor, MI.</li><br>
            <li>Ripley, B. (1996). Pattern recognition and neural networks. Cambridge, UK: Cambridge
University Press.</li><br>
            <li>Ripley, B. (1996). Pattern recognition and neural networks. Cambridge, UK: Cambridge
University Press.</li><br>
            <li>Roth, P. (1994). Missing data: A conceptual review for applied psychologists. Personnel
Psychology, 47, 537-560.</li><br>
            <li>Royall, R. & Herson, J. (1973). Robust estimation from finite populations. Journal of the
American Statistical Association. 68, 883-889.</li><br>
             <li>Rubin, D. (1978). Multiple imputations in sample surveys - A phenomenological
Bayesian approach to nonresponse, Imputation and Editing of Faulty or Missing
Survey Data, U.S. Department of Commerce, 1-23.</li><br>
             <li>Rubin, D. (1986). Statistical matching using file concatenation with adjusted weights and
multiple imputations. Journal of Business and Economic Statistics, 4, 87-94.</li><br>
             <li>Rubin, D. (1996). Multiple imputation after 18+ years (with discussion. Journal of the
American Statistical Association, 91, 473-489.</li><br>
             <li>Rubin, D. & Schenker, N. (1986). Multiple imputation for interval estimation from simple
random sample with ignorable nonresponse, Journal of the American Statistical
Association, 81, 366-374.</li><br>
            <li>Sande, L. (1982). Imputation in surveys: Coping with reality. The American Statistician,
Vol. 36, 145-152.</li><br>
            <li>Sande, L. (1983). Hot-deck imputation procedures. In W.G. Madow & I. Olkin (eds.),
Incomplete data in sample surveys, Vol. 3, Proceedings of the Symposium on
Incomplete Data: Panel on Incomplete Data, Committee of National Statistics,
Commission on Behavioral and Social Sciences and Education, National Research Council, Washington, D. C., 1979, August 10-11, pp. 339-349. New York:
Academic Press.</li><br>
            <li>Schafer, J. (1997). Analysis of incomplete multivariate data. London: Chapman and Hall.
Schafer, J. (1999). Mult</li><br>
            <li>Schafer, J. (1999). Multiple imputation: A primer. Statistical Methods in Medical
Research, 8, 3-15.</li><br>
            <li>Schafer, J. & Olsen, M. (1998). Multiple imputation for multivariate missing-data
problems: A data analyst’s perspective. Multivariate Behavioral Research, 33,
545-571.</li><br>
            <li>Sharpe, P. & Glover, R. (1999). Efficient GA based techniques for classification, Applied
Intelligence, 11, 3, 277-284.</li><br>
            <li>Skapura, D. (1995). Building neural networks. New York: Addison Wesley.</li><br>
            <li>Statistical Services of University of Texas (2000). General FAQ #25: Handling missing
or incomplete data [Online]. Available http://www.utexas.edu/cc/faqs/stat/general/gen25.html. [2001, September 1].</li><br>
            <li>Sullivan, D. (2001). Document warehousing and text mining. New York: John Wiley &
Sons.</li><br>
            <li>Szpiro, G. (1997). A search for hidden relationships: Data mining with genetic algorithms,
Computational Economics, 10, 3, 267-277.</li><br>
            <li>Tresp, V., Neuneier, R., & Ahmad, S. (1995). Efficient methods for dealing with missing
data in supervised learning. In G. Tesauro, D. Touretzky, and T. Keen (eds.),
Advances in neural information processing systems 7. pp. 689-696. Cambridge,
MA: The MIT Press.</li><br>
            <li>van Buren, S., Boshuizen, H., & Knook, D. (1999). Multiple imputation of missing blood
pressure covariates in survival analysis. Statistics in Medicine, 18, 681-694.
</li><br>
            <li>Warner, B., & Misra, M. (1996). Understanding neural networks as statistical tools. The
American Statistician, 50, 284-293.</li><br>
            <li>Westphal, C. & Blaxton, T. (1998). Data mining solutions. New York: Wiley.</li><br>
            <li>Witten, I. & Frank, E. (2000). Data mining. San Francisco: Academic Press.</li><br>
            <li>Wothke, W. (1998). Longitudinal and multi-group modeling with missing data. In T.D.
Little, K.U. Schnabel, & J. Baumert (eds.), Modelling longitudinal and multiple
group data: Practical issues, applied approaches and specific examples. Mahwah,
NJ: Lawrence Erlbaum Associates</li><br>
        </ul>
        <center>
        <h2>Chapter VIII</h2>
        <h1>Mining Text Documents</h1>
            <h1>for Thematic Hierarchies</h1>
            <h1>Using Self-Organizing</h1>
     <h1> Maps</h1>
            <h4>Hsin-Chang Yang</h4>
<h4>Chang Jung University, Taiwan</h4>
            <h4>Chung-Hong Lee</h4>
<h4>Chang Jung University, Taiwan</h4>
            <br><br>
            <h2>ABSTRACT</h2>
            <p>&nbsp;&nbsp;&nbsp;&nbsp;Recently, many approaches have been devised for mining various kinds of knowledge
from texts. One important application of text mining is to identify themes and the
semantic relations among these themes for text categorization. Traditionally, these
themes were arranged in a hierarchical manner to achieve effective searching and
indexing as well as easy comprehension for human beings. The determination of
category themes and their hierarchical structures was mostly done by human experts.
In this work, we developed an approach to automatically generate category themes and
reveal the hierarchical structure among them. We also used the generated structure to
categorize text documents. The document collection was trained by a self-organizing
map to form two feature maps. We then analyzed these maps and obtained the category
themes and their structure. Although the test corpus contains documents written in
Chinese, the proposed approach can be applied to documents written in any language,
and such documents can be transformed into a list of separated terms</p>
        </center>
        <center>
        <h1>INTRODUCTION</h1>
            <p>&nbsp;&nbsp;&nbsp;&nbsp;In text categorization, we try to assign a text document to some predefined category.
When a set of documents is well categorized, both storage and retrieval of these
documents can be effectively achieved. A primary characteristic of text categorization
is that a category reveals the common theme of those documents under this category;
that is, these documents form a natural cluster of similar context. Thus, text categorization
provides some knowledge about the document collection. An interesting argument
about text categorization is that before we can acquire knowledge through text categorization, we need some kinds of knowledge to correctly categorize documents. For
example, two kinds of key knowledge we need to perform text categorization are 1) the
categories that we can use, and 2) the relationships among the categories. The first kind
of knowledge provides a set of themes that we can use to categorize documents. Similar
documents will be categorized under the same category if they have the same theme.
These categories form the basis of text categorization. The second kind of knowledge
reveals the structure among categories according to their semantic similarities. Ideally,
similar categories, i.e., categories with similar themes, will be arranged “closely” within
the structure in some manner. Such arrangement provides us with an effective way to
store and retrieve documents. Moreover, such structure may make the categorization
                result more comprehensible by humans.</p>
             <p>&nbsp;&nbsp;&nbsp;&nbsp;Traditionally, human experts or some semi-automatic mechanisms that incorporate
human knowledge and computing techniques such as natural language processing
provided these kinds of knowledge. For example, the MEDLINE corpus required considerable human effort to carry out categorization using a set of Medical Subject Headings
(MeSH) categories (Mehnert, 1997). However, fully automatic generation of categories
and their structure are difficult for two reasons. First, we need to select some important
words as category terms (or category themes). We use these words to represent the
themes of categories and to provide indexing information for the categorized documents.
Generally, a category term contains only a single word or a phrase. The selection of the
terms will affect the categorization result as well as the effectiveness of the categorization. A proper selection of a category term should be able to represent the general idea
of the documents under the corresponding category. Such selections were always done
by human linguistic experts because we need an insight of the underlying semantic
structure of a language to make the selections. Unfortunately, such insight is hard to
automate. Certain techniques such as word frequency counts may help, but it is the
human experts who finally decide what terms are most discriminative and representative.
Second, for the ease of human comprehension, the categories were always arranged in
a tree-like hierarchical structure. This hierarchy reveals the relationships among categories. A category associated with higher-level nodes of the hierarchy represents a more
general theme than those associated with lower level nodes. Also, a parent category in
the hierarchy should represent the common theme of its child categories. The retrieval
of documents of a particular interest can be effectively achieved through such hierarchy.
Although the hierarchical structure is ideal for revealing the similarities among categories, the hierarchy must be constructed carefully such that irrelevant categories may not
be the children of the same parent category. A thorough investigation of the semantic
relations among category terms must be conducted to establish a well-organized
hierarchy. This process is also hard to automate. Therefore, most of text categorization
</p>
            
        </center>
        
        
            
    </body>
</html>